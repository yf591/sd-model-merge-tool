{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yf591/sd-model-merge-tool/blob/main/04_Merge_Model_Maker_Ver2_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3モデル以上単純マージ（Hugging Face用）"
      ],
      "metadata": {
        "id": "JlKkvOM93yjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cFnNeISribud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### ライブラリのインストールと準備\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "# Hugging Face Hub, PyTorch, その他必要なライブラリをインストール\n",
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 # PyTorchを使用して深層学習モデルを操作します。CUDAバージョン（例: `cu118`）を指定\n",
        "!pip install diffusers transformers accelerate # Stable Diffusionを扱うための主要ライブラリです。モデルのロードや画像生成の操作を簡素化\n",
        "!pip install safetensors # 安全かつ軽量なモデル保存形式（`.safetensors`）をサポート\n",
        "!pip install huggingface-hub # Hugging Face Hubからモデルをダウンロード・管理\n",
        "!pip install opencv-python # 生成した画像の前処理や後処理に使用\n",
        "!pip install numpy # 数値計算ライブラリで、モデルや画像の操作に使う\n",
        "!pip install matplotlib # 生成された画像の可視化に使う\n",
        "!pip install tqdm # プログレスバーの表示\n",
        "!pip install optuna # ハイパーパラメータ最適化\n",
        "!pip install requests\n",
        "\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "fGB3APsEHB9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 必要なライブラリのインポート\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from safetensors.torch import load_file, save_file\n",
        "from transformers import AutoConfig, AutoModel\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline, UNet2DConditionModel\n",
        "import shutil\n",
        "from huggingface_hub import hf_hub_download\n",
        "from typing import List, Dict\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image, clear_output\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import uuid"
      ],
      "metadata": {
        "id": "qgSmdhyqG6ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### APIキー設定（Hugging Face, Civitai）\n",
        "\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# Hugging Faceで取得したTokenをこちらに貼る(トークンを非表示で入力)\n",
        "HF_TOKEN = getpass(\"Hugging FaceのRead権限のあるHF Tokenを入力してください: \")\n",
        "\n",
        "# CIVITAI_TOKEN が存在する場合、取得\n",
        "api_key = userdata.get('CIVITAI_TOKEN')\n",
        "if api_key is None:\n",
        "    print(\"Error: CIVITAI_API_KEY secret is not set.\")"
      ],
      "metadata": {
        "id": "fVJiJSqFie1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HXUgZo5rQC4"
      },
      "outputs": [],
      "source": [
        "#@title ### 関数の定義（モデルのダウンロードとロード）\n",
        "\n",
        "def download_model(repo_id, filename, token):\n",
        "    \"\"\"Hugging Face Hubからモデルをダウンロード\"\"\"\n",
        "    return hf_hub_download(repo_id=repo_id, filename=filename, token=token)\n",
        "\n",
        "def download_civitai_model(url, output_path, api_key):\n",
        "    \"\"\"Civitaiからモデルをダウンロード\"\"\"\n",
        "    try:\n",
        "        headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else None\n",
        "        response = requests.get(url, stream=True, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        with open(output_path, 'wb') as file, tqdm(\n",
        "            desc=output_path,\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as bar:\n",
        "             for data in response.iter_content(chunk_size=1024):\n",
        "                size = file.write(data)\n",
        "                bar.update(size)\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading from Civitai: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_model(path, device, api_key=None):\n",
        "    \"\"\"ファイルパスまたはURLからモデルをロードする\"\"\"\n",
        "    try:\n",
        "        if path.startswith(\"http\"):\n",
        "            # URLの場合（Civitaiなど）は、ダウンロードしてから読み込む\n",
        "            if \"civitai.com\" in path:\n",
        "                unique_id = str(uuid.uuid4())\n",
        "                output_path = f\"/content/downloaded_models/model_{unique_id}.safetensors\"\n",
        "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "                downloaded_path = download_civitai_model(path, output_path, api_key)\n",
        "                if not downloaded_path:\n",
        "                   return None\n",
        "                else:\n",
        "                   print(f\"Civitaiからモデルをロード: {downloaded_path}\")\n",
        "                   return load_file(downloaded_path, device=device) #ダウンロード後のファイルパスを渡す。\n",
        "            elif \"huggingface.co\" in path:\n",
        "                print(f\"HuggingFaceからモデルをロード: {path}\")\n",
        "                repo_id_and_file = path.split(\"huggingface.co/\")[1]\n",
        "                repo_id = repo_id_and_file.split(\"/resolve/\")[0]\n",
        "                filename = repo_id_and_file.split(\"/\")[-1]\n",
        "                path = download_model(repo_id, filename, HF_TOKEN)\n",
        "                return load_file(path, device=device)\n",
        "            else:\n",
        "                print(\"Error: HTTP URL not recognized, use HuggingFace or Civitai Model.\")\n",
        "                return None\n",
        "\n",
        "        if path.startswith(\"/content/drive\"):\n",
        "          # Google Drive のパスの場合\n",
        "            print(f\"Google Driveからモデルをロード: {path}\")\n",
        "            return load_file(path, device=device)\n",
        "        else:\n",
        "          print(\"Error: Incorrect Model Path.\")\n",
        "          return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 関数の定義（モデルのマージとテスト、保存関数）\n",
        "\n",
        "def merge_multiple_models(models: List[Dict]):\n",
        "    \"\"\"複数のモデルを単純マージ（テンソルサイズが異なる場合を処理）\"\"\"\n",
        "    merged_weights = {}\n",
        "\n",
        "    # 初期モデルのキー構造を取得\n",
        "    base_model_keys = set(models[0]['weights'].keys())\n",
        "\n",
        "    for key in base_model_keys:\n",
        "        weights_to_merge = []\n",
        "        valid_alphas = []\n",
        "\n",
        "        for model in models:\n",
        "            weights = model['weights']\n",
        "            if key in weights:\n",
        "                # テンソルサイズの一致を確認\n",
        "                if weights[key].size() == models[0]['weights'][key].size():\n",
        "                    weights_to_merge.append(weights[key])\n",
        "                    valid_alphas.append(model['alpha'])\n",
        "                else:\n",
        "                    print(f\"警告: レイヤー {key} のサイズが一致しません。スキップします。\")\n",
        "\n",
        "        if weights_to_merge:\n",
        "            merged_weights[key] = sum(\n",
        "                alpha * weight for alpha, weight in zip(valid_alphas, weights_to_merge)\n",
        "            ) / sum(valid_alphas)\n",
        "        else:\n",
        "            # レイヤー構造が一致しない場合、最初のモデルの重みを使用\n",
        "            print(f\"情報: レイヤー {key} に対応する重みが見つからないため、最初のモデルの重みを使用します。\")\n",
        "            merged_weights[key] = models[0]['weights'][key]\n",
        "\n",
        "    return merged_weights\n",
        "\n",
        "def test_model_memory(merged_weights, test_function):\n",
        " \"\"\"メモリ上のモデルでテスト\"\"\"\n",
        " try:\n",
        "     test_results = test_function(merged_weights)\n",
        "     print(\"テスト結果:\", test_results)\n",
        "     if test_results and test_results.startswith(\"テスト成功:\"):\n",
        "         display(Image(filename=test_results.split(\":\",1)[1].strip()))\n",
        " except Exception as e:\n",
        "     print(f\"テスト中にエラーが発生しました: {e}\")\n",
        "\n",
        "def save_merged_model(merged_weights, output_path):\n",
        "    \"\"\"マージ済みモデルを保存\"\"\"\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    save_file(merged_weights, output_path)"
      ],
      "metadata": {
        "id": "bcy3HGAckrvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### Diffusers形式での保存関数\n",
        "\n",
        "def save_merged_weights_as_diffusers_format(merged_weights, output_dir):\n",
        "    \"\"\"マージ済みの重みをDiffusers形式で保存\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    # UNetモデルのコンフィグを取得\n",
        "    config = AutoConfig.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", force_download=True)\n",
        "    # configにmodel_typeを追加\n",
        "    config.model_type = \"unet\"\n",
        "    # コンフィグからUNet2DConditionModelを生成\n",
        "    model = UNet2DConditionModel.from_config(config)\n",
        "    # マージされた重みを適用\n",
        "    model.load_state_dict(merged_weights, strict=False)\n",
        "    # Diffusers形式でモデルを保存\n",
        "    model.save_pretrained(output_dir)\n",
        "    print(f\"マージ済みモデルを {output_dir} に保存しました。\")"
      ],
      "metadata": {
        "id": "mdmsQbf0k0Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### テスト用画像生成関数\n",
        "\n",
        "def example_test_function(weights):\n",
        "    \"\"\"画像生成をテストする関数\"\"\"\n",
        "    try:\n",
        "        positive_prompt = positive_prompt_widget.value\n",
        "        negative_prompt = negative_prompt_widget.value\n",
        "\n",
        "        print(\"ポジティブプロンプト:\", positive_prompt)\n",
        "        print(\"ネガティブプロンプト:\", negative_prompt)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # UNetモデルのコンフィグを取得\n",
        "            config = AutoConfig.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", force_download=True)\n",
        "            # コンフィグからUNet2DConditionModelを生成\n",
        "            unet = UNet2DConditionModel.from_config(config)\n",
        "            unet.load_state_dict(weights, strict=False)\n",
        "\n",
        "            # パイプラインをロード\n",
        "            pipe = DiffusionPipeline.from_pretrained(\n",
        "                \"CompVis/stable-diffusion-v1-4\",\n",
        "                unet=unet,\n",
        "                torch_dtype=torch.float32,\n",
        "                safety_checker=None\n",
        "            ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "            pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "            # 画像生成\n",
        "            image = pipe(\n",
        "                prompt=positive_prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                guidance_scale=7.5,\n",
        "                num_inference_steps=10,\n",
        "                width=128,\n",
        "                height=128,\n",
        "            ).images[0]\n",
        "            del unet\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "        # 生成画像を表示\n",
        "        temp_path = \"/content/temp_test_image.png\"\n",
        "        image.save(temp_path)\n",
        "\n",
        "        return f\"テスト成功: {temp_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"テスト失敗: {e}\""
      ],
      "metadata": {
        "id": "iTMxuELHk4rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### UI設定\n",
        "\n",
        "# UI設定\n",
        "paths = [\n",
        "    widgets.Text(value=\"https://huggingface.co/sazyou-roukaku/chilled_remix/resolve/main/chilled_remix_v2.safetensors\", description=\"Path1\", layout=widgets.Layout(width='90%')),\n",
        "    widgets.Text(value=\"/content/drive/MyDrive/sd-webui-google-colab-setup/stable-diffusion-webui/models/checkpoints/merged_model_chillre_majic.safetensors\", description=\"Path2\", layout=widgets.Layout(width='90%')),\n",
        "    widgets.Text(value=\"https://civitai.com/api/download/models/279964?type=Model&format=SafeTensor&size=full&fp=fp16\", description=\"Path3\", layout=widgets.Layout(width='90%')),\n",
        "    widgets.Text(value=\"https://civitai.com/api/download/models/90505?type=Model&format=SafeTensor&size=full&fp=fp32\", description=\"Path4\", layout=widgets.Layout(width='90%')),\n",
        "    widgets.Text(value=\"\", description=\"Path5\", layout=widgets.Layout(width='90%')),\n",
        "]\n",
        "\n",
        "sliders = [\n",
        "    widgets.FloatSlider(value=0.15, min=0, max=1, step=0.01, description=\"Alpha1\"),\n",
        "    widgets.FloatSlider(value=0.20, min=0, max=1, step=0.01, description=\"Alpha2\"),\n",
        "    widgets.FloatSlider(value=0.35, min=0, max=1, step=0.01, description=\"Alpha3\"),\n",
        "    widgets.FloatSlider(value=0.30, min=0, max=1, step=0.01, description=\"Alpha4\"),\n",
        "    widgets.FloatSlider(value=0.0, min=0, max=1, step=0.01, description=\"Alpha5\"),\n",
        "]\n",
        "\n",
        "\n",
        "positive_prompt_widget = widgets.Text(value=\"extremely detailed CG, 8k, masterpiece, best quality, hyperrealistic, sharp focus, intricate details, professional art, perfect lighting, ultra high res, a cute girl in the office, RAW photo, no artifacts, best quality\", description=\"Positive Prompt\", layout=widgets.Layout(width='90%'))\n",
        "negative_prompt_widget = widgets.Text(value=\"low quality, blurry, pixelated, distorted, bad anatomy, disfigured, out of focus, bad proportions, skin blemishes, low contrast, text, logo, watermark, ((monochrome:1.5)), ((grayscale:1.5)), ((cartoon:1.2)), ((anime:1.2)), ((3d:1.2)), ((skin spots:1.3)), ((acnes:1.3)), ((age spots:1.3))\", description=\"Negative Prompt\", layout=widgets.Layout(width='90%'))\n",
        "\n",
        "def enforce_alpha_constraints(*args):\n",
        "    total_alpha = sum(slider.value for slider in sliders)\n",
        "    if total_alpha > 1.0:\n",
        "        for slider in sliders:\n",
        "            slider.value = slider.value / total_alpha\n",
        "\n",
        "for slider in sliders:\n",
        "    slider.observe(enforce_alpha_constraints, 'value')\n",
        "\n",
        "\n",
        "output_file_widget = widgets.Text(value=\"/content/drive/MyDrive/sd-webui-google-colab-setup/stable-diffusion-webui/models/checkpoints/merged_model_4samples.safetensors\", description=\"Output\", layout=widgets.Layout(width='90%'))"
      ],
      "metadata": {
        "id": "v9vaC-RflEGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### マージ実行関数\n",
        "def execute_merge():\n",
        "    model_paths_and_alphas = []\n",
        "\n",
        "    for path, slider in zip(paths, sliders):\n",
        "      if path.value and slider.value > 0:\n",
        "          model_paths_and_alphas.append({\n",
        "              \"path\": path.value,\n",
        "              \"alpha\": slider.value\n",
        "          })\n",
        "\n",
        "\n",
        "    output_file = output_file_widget.value\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            models = []\n",
        "\n",
        "            for item in model_paths_and_alphas:\n",
        "                print(f\"モデルをロード中: {item['path']}\")\n",
        "                weights = load_model(item['path'], device=\"cuda\" if torch.cuda.is_available() else \"cpu\", api_key=api_key)\n",
        "                if weights is not None:\n",
        "                    models.append({\"weights\": weights, \"alpha\": item['alpha']})\n",
        "                else:\n",
        "                    print(f\"Error: model loading failed. Skip this model.\")\n",
        "\n",
        "            if not models:\n",
        "                print(\"Error: No valid models to merge.\")\n",
        "                return\n",
        "\n",
        "            for idx, model in enumerate(models):\n",
        "                print(f\"model{idx + 1} keys: {list(model['weights'].keys())[:5]} ...\")\n",
        "\n",
        "            print(\"モデルをマージ中...\")\n",
        "            merged_weights = merge_multiple_models(models)\n",
        "\n",
        "            print(\"メモリ上のモデルでテスト中...\")\n",
        "            test_model_memory(merged_weights, example_test_function)\n",
        "\n",
        "            confirm_button = widgets.Button(description=\"画像が気に入ったら保存\")\n",
        "            retry_button = widgets.Button(description=\"重みを再調整\")\n",
        "\n",
        "            def on_confirm_clicked(b):\n",
        "                print(f\"マージ済みモデルを保存します: {output_file}\")\n",
        "                save_merged_model(merged_weights, output_file)\n",
        "                print(\"マージ完了！\")\n",
        "                confirm_button.close()\n",
        "                retry_button.close()\n",
        "                return\n",
        "\n",
        "            def on_retry_clicked(b):\n",
        "                print(\"重みを再調整してください。\")\n",
        "                clear_output()\n",
        "                display(ui, output_file_widget, merge_button)\n",
        "\n",
        "            confirm_button.on_click(on_confirm_clicked)\n",
        "            retry_button.on_click(on_retry_clicked)\n",
        "\n",
        "            display(confirm_button, retry_button)\n",
        "            break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"エラーが発生しました: {e}\")\n",
        "            if \"key\" in locals() and \"weights\" in locals():\n",
        "                print(f\"Skipped key: {key}, Error: {e}\")"
      ],
      "metadata": {
        "id": "XxRjApYAxnR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### UIの表示と実行ボタン\n",
        "\n",
        "ui = widgets.VBox(paths + sliders + [positive_prompt_widget, negative_prompt_widget])\n",
        "merge_button = widgets.Button(description=\"マージ実行\")\n",
        "merge_button.on_click(lambda x: execute_merge())\n",
        "\n",
        "display(ui, output_file_widget, merge_button)"
      ],
      "metadata": {
        "id": "kyRgPsbtlHSj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}