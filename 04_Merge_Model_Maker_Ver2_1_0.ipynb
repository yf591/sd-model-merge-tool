{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yf591/sd-model-merge-tool/blob/main/04_Merge_Model_Maker_Ver2_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3モデル以上の階層マージ（Huggin Face, Civitai, MyDriveからのロードに対応）"
      ],
      "metadata": {
        "id": "JlKkvOM93yjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 事前準備"
      ],
      "metadata": {
        "id": "ByktfT4hb7F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NqUI0ImphRfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "\n",
        "# Hugging Face Hub, PyTorch, その他必要なライブラリをインストール\n",
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 # PyTorchを使用して深層学習モデルを操作します。CUDAバージョン（例: `cu118`）を指定\n",
        "!pip install diffusers transformers accelerate # Stable Diffusionを扱うための主要ライブラリです。モデルのロードや画像生成の操作を簡素化\n",
        "!pip install safetensors # 安全かつ軽量なモデル保存形式（`.safetensors`）をサポート\n",
        "!pip install huggingface-hub # Hugging Face Hubからモデルをダウンロード・管理\n",
        "!pip install opencv-python # 生成した画像の前処理や後処理に使用\n",
        "!pip install numpy # 数値計算ライブラリで、モデルや画像の操作に使う\n",
        "!pip install matplotlib # 生成された画像の可視化に使う\n",
        "!pip install tqdm # プログレスバーの表示\n",
        "!pip install optuna # ハイパーパラメータ最適化\n",
        "\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "fGB3APsEHB9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline, UNet2DConditionModel\n",
        "from safetensors.torch import load_file, save_file\n",
        "from transformers import AutoConfig, AutoModel\n",
        "from huggingface_hub import hf_hub_download\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from typing import List, Dict\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "import time"
      ],
      "metadata": {
        "id": "y0Ygu2nkLyYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### APIキー設定（Hugging Face, Civitai）\n",
        "\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# Hugging Faceで取得したTokenをこちらに貼る(トークンを非表示で入力)\n",
        "HF_TOKEN = getpass(\"Hugging FaceのRead権限のあるHF Tokenを入力してください: \")\n",
        "\n",
        "# CIVITAI_TOKEN が存在する場合、取得\n",
        "api_key = userdata.get('CIVITAI_TOKEN')\n",
        "if api_key is None:\n",
        "    print(\"Error: CIVITAI_API_KEY secret is not set.\")"
      ],
      "metadata": {
        "id": "Z3seSHs5hZTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 各種設定（関数の定義、モデル数の設定）"
      ],
      "metadata": {
        "id": "r8wL017Gcsiy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HXUgZo5rQC4"
      },
      "outputs": [],
      "source": [
        "#@title ### 関数の定義\n",
        "\n",
        "# ヘルパー関数\n",
        "def download_model(repo_id, filename, token):\n",
        "    \"\"\"Hugging Face Hubからモデルをダウンロード\"\"\"\n",
        "    return hf_hub_download(repo_id=repo_id, filename=filename, token=token)\n",
        "\n",
        "\n",
        "def get_model_filename_from_url(url):\n",
        "    \"\"\"URLからモデル名を抽出する\"\"\"\n",
        "    parsed_url = urlparse(url)\n",
        "    # パスの最後の部分をファイル名として使用\n",
        "    filename = os.path.basename(parsed_url.path)\n",
        "    # ファイル名が無い場合はデフォルト名を使用\n",
        "    if not filename or not filename.endswith('.safetensors'):\n",
        "        filename = f\"model_{hash(url)}.safetensors\"\n",
        "    return filename\n",
        "\n",
        "def download_civitai_model(url, output_dir=\"/content/downloaded_models\", api_key=None):\n",
        "    \"\"\"Civitaiからモデルをダウンロード（一意のファイル名を使用）\"\"\"\n",
        "    try:\n",
        "        # 出力ディレクトリが存在しない場合は作成\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # URLからファイル名を取得\n",
        "        filename = get_model_filename_from_url(url)\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "        # 既にダウンロード済みの場合はそのパスを返す\n",
        "        if os.path.exists(output_path):\n",
        "            print(f\"モデルは既にダウンロード済みです: {output_path}\")\n",
        "            return output_path\n",
        "\n",
        "        print(f\"モデルをダウンロードしています: {filename}\")\n",
        "        headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else None\n",
        "        response = requests.get(url, stream=True, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        with open(output_path, 'wb') as file, tqdm(\n",
        "            desc=filename,\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as bar:\n",
        "            for data in response.iter_content(chunk_size=1024):\n",
        "                size = file.write(data)\n",
        "                bar.update(size)\n",
        "\n",
        "        print(f\"ダウンロード完了: {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Civitaiからのダウンロード中にエラーが発生しました: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_model(path, device):\n",
        "    \"\"\"ファイルパスからモデルをロードする（修正版）\"\"\"\n",
        "    try:\n",
        "        if path.startswith(\"http\"):\n",
        "            if \"civitai.com\" in path:\n",
        "                output_path = download_civitai_model(path, api_key=api_key)\n",
        "                if not output_path:\n",
        "                    return None\n",
        "                print(f\"Civitaiからモデルをロード: {output_path}\")\n",
        "                try:\n",
        "                    return load_file(output_path, device=device)\n",
        "                except Exception as e:\n",
        "                  print(f\"Error loading downloaded Civitai model: {e}. Attempting to redownload...\")\n",
        "                  os.remove(output_path)\n",
        "                  output_path = download_civitai_model(path, api_key=api_key)\n",
        "                  if not output_path:\n",
        "                     return None\n",
        "                  return load_file(output_path, device=device)\n",
        "            elif \"huggingface.co\" in path:\n",
        "                print(f\"HuggingFaceからモデルをロード: {path}\")\n",
        "                repo_id_and_file = path.split(\"huggingface.co/\")[1]\n",
        "                repo_id = repo_id_and_file.split(\"/resolve/\")[0]\n",
        "                filename = repo_id_and_file.split(\"/\")[-1]\n",
        "                path = download_model(repo_id, filename, HF_TOKEN)\n",
        "                return load_file(path, device=device)\n",
        "            else:\n",
        "                print(\"Error: HTTP URLが認識できません。HuggingFaceまたはCivitaiのモデルを使用してください。\")\n",
        "                return None\n",
        "\n",
        "        if path.startswith(\"/content/drive\"):\n",
        "            print(f\"Google Driveからモデルをロード: {path}\")\n",
        "            return load_file(path, device=device)\n",
        "        else:\n",
        "            print(\"Error: モデルパスが正しくありません。\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"モデルのロード中にエラーが発生しました: {e}\")\n",
        "        return None\n",
        "\n",
        "def merge_multiple_models(models: List[Dict], alpha, layer_sliders, use_alpha_checkboxes):\n",
        "    \"\"\"複数のモデルを階層マージする（修正版）\"\"\"\n",
        "    merged_weights = {}\n",
        "\n",
        "    # 最初のモデルのキー構造を取得 # U-Netモデルの各レイヤー名と構造を把握するため\n",
        "    base_model_keys = set(models[0]['weights'].keys())\n",
        "    skipped_layers = []\n",
        "\n",
        "    for key in base_model_keys: # U-Netの全ての重みに対して処理を実行\n",
        "        weights_to_merge = []\n",
        "        valid_alphas = []\n",
        "\n",
        "        # キーから層の名前を抽出 # 例: model.diffusion_model.input_blocks.4.1.proj_in.weight\n",
        "        layer_type = None # レイヤーの種類(IN, M, OUT)\n",
        "        if 'input_blocks' in key: # U-Netのエンコーダー部分\n",
        "            layer_type = 'IN'\n",
        "        elif 'middle_block' in key: # U-Netの中間層\n",
        "            layer_type = 'M'\n",
        "        elif 'output_blocks' in key: # U-Netのデコーダー部分\n",
        "            layer_type = 'OUT'\n",
        "\n",
        "        # 層番号の抽出（存在する場合）\n",
        "        layer_num = None # レイヤーの番号 (例: IN04)\n",
        "        if layer_type:\n",
        "            try:\n",
        "                if layer_type == 'M': # middle_blockは00固定\n",
        "                    layer_num = '00'\n",
        "                else:\n",
        "                    # キーから数字を抽出\n",
        "                    parts = key.split('.')\n",
        "                    for part in parts:\n",
        "                        if part.isdigit():\n",
        "                            layer_num = str(part).zfill(2)\n",
        "                            break\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # 完全な層名を構築（例: \"IN04\"）\n",
        "        layer_name = f\"{layer_type}{layer_num}\" if layer_type and layer_num else None # 例: input_blocksの4番目のレイヤーなら IN04\n",
        "\n",
        "        try:\n",
        "            for idx, model in enumerate(models): # 各モデルの重みを収集\n",
        "                weights = model['weights']\n",
        "                if key in weights and weights[key].size() == models[0]['weights'][key].size(): # 重みのサイズが一致する場合\n",
        "                    weights_to_merge.append(weights[key])\n",
        "                    valid_alphas.append(model['alpha'])\n",
        "                else:\n",
        "                    print(f\"警告: レイヤー {key} のサイズが一致しないか存在しません。スキップします。\")\n",
        "                    skipped_layers.append(key)\n",
        "                    break\n",
        "\n",
        "            if weights_to_merge: # マージする重みが存在する場合\n",
        "                if layer_name and layer_name in use_alpha_checkboxes: # レイヤー名が存在し、かつチェックボックスがUIにある場合\n",
        "                    if use_alpha_checkboxes[layer_name].value: # チェックボックスがTrueの場合、グローバルalphaを使用\n",
        "                        # グローバルアルファ値を使用\n",
        "                        merged_weights[key] = sum(\n",
        "                            alpha * weight for alpha, weight in zip(valid_alphas, weights_to_merge)\n",
        "                        )\n",
        "                    else: # チェックボックスがFalseの場合、レイヤー固有のスライダーの値を使用\n",
        "                        # レイヤー固有のスライダー値を使用\n",
        "                        layer_alphas = []\n",
        "                        sliders = layer_sliders.get(layer_name, []) # レイヤーに対応するスライダーを取得\n",
        "\n",
        "                        # スライダー値の取得\n",
        "                        for i in range(len(weights_to_merge) - 1):\n",
        "                            if i < len(sliders):\n",
        "                                layer_alphas.append(sliders[i].value) # スライダーの値を収集\n",
        "                            else:\n",
        "                                layer_alphas.append(1.0 / len(weights_to_merge)) # スライダーが無い場合はデフォルト値\n",
        "\n",
        "                        # 最後のアルファ値を計算\n",
        "                        last_alpha = 1.0 - sum(layer_alphas)\n",
        "                        layer_alphas.append(last_alpha)\n",
        "\n",
        "                        # 重みの合計を計算\n",
        "                        merged_weights[key] = sum(\n",
        "                            alpha * weight for alpha, weight in zip(layer_alphas, weights_to_merge)\n",
        "                        )\n",
        "                else: # レイヤー名がUIに存在しない場合はグローバルalphaを使用\n",
        "                    # レイヤー名が見つからない場合はグローバルアルファ値を使用\n",
        "                    merged_weights[key] = sum(\n",
        "                        alpha * weight for alpha, weight in zip(valid_alphas, weights_to_merge)\n",
        "                    )\n",
        "            else:\n",
        "                print(f\"情報: レイヤー {key} に対応する重みが見つかりません。最初のモデルの重みを使用します。\")\n",
        "                merged_weights[key] = models[0]['weights'][key] # 重みが見つからない場合は、最初のモデルの重みを使用\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipped key: {key}, Error: {e}\")\n",
        "            skipped_layers.append(key)\n",
        "            merged_weights[key] = models[0]['weights'][key]\n",
        "\n",
        "    if skipped_layers:\n",
        "        print(\"\\nスキップされたレイヤーの数:\", len(skipped_layers))\n",
        "        print(\"スキップされたレイヤーの例:\", skipped_layers[:5])\n",
        "\n",
        "    return merged_weights\n",
        "\n",
        "\n",
        "def save_merged_model(merged_weights, output_path):\n",
        "    \"\"\"マージ済みモデルを保存\"\"\"\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    save_file(merged_weights, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MergeするModel数の定義\n",
        "\n",
        "# UI設定\n",
        "num_models = 5 #@param {type:\"integer\"}\n",
        "paths = [widgets.Text(value=\"\", description=f\"Path{i+1}\", layout=widgets.Layout(width='80%')) for i in range(num_models)]\n",
        "sliders = [widgets.FloatSlider(value=1/num_models, min=0, max=1, step=0.01, description=f\"Alpha{i+1}\") for i in range(num_models-1)]\n",
        "alpha_n = widgets.FloatText(value=1-sum([slider.value for slider in sliders]), description=f\"Alpha{num_models}\", disabled = True)\n",
        "\n",
        "def enforce_alpha_constraints(*args):\n",
        "    total_alpha = sum(slider.value for slider in sliders)\n",
        "    alpha_n.value = 1 - total_alpha\n",
        "\n",
        "for slider in sliders:\n",
        "    slider.observe(enforce_alpha_constraints, 'value')\n",
        "\n",
        "output_file_widget = widgets.Text(value=\"/content/drive/MyDrive/sd-webui-google-colab-setup/stable-diffusion-webui/models/checkpoints/merged_model_kaisou_sample1.safetensors\", description=\"Output\", layout=widgets.Layout(width='80%'))\n",
        "\n",
        "\n",
        "# UI設定 (レイヤーごとのスライダーを追加)\n",
        "layer_names = [\n",
        "    \"IN00\", \"IN01\", \"IN02\", \"IN03\", \"IN04\", \"IN05\", \"IN06\", \"IN07\", \"IN08\", \"IN09\", \"IN10\", \"IN11\",\n",
        "    \"M00\",\n",
        "    \"OUT00\", \"OUT01\", \"OUT02\", \"OUT03\", \"OUT04\", \"OUT05\", \"OUT06\", \"OUT07\", \"OUT08\", \"OUT09\", \"OUT10\", \"OUT11\"\n",
        "]\n",
        "layer_sliders = {}\n",
        "use_alpha_checkboxes = {}\n",
        "for layer in layer_names:\n",
        "    layer_sliders[layer] = [widgets.FloatSlider(value=1/num_models, min=0, max=1, step=0.01, description=f\"{layer}_{i+1}\") for i in range(num_models-1)]\n",
        "    # 自動計算されるFloatTextの初期値を設定\n",
        "    layer_sliders[layer].append(widgets.FloatText(value=1-sum(1/num_models for i in range(num_models-1)), description = f\"{layer}_{num_models}\", disabled = True))\n",
        "    use_alpha_checkboxes[layer] = widgets.Checkbox(value=False, description=f\"Alphaを優先({layer})\")\n",
        "    def enforce_layer_slider_constraints(change, layer_name = layer):\n",
        "         total_value = sum([slider.value for slider in layer_sliders[layer_name][:-1]])\n",
        "         layer_sliders[layer_name][-1].value = 1 - total_value\n",
        "    for slider in layer_sliders[layer][:-1]:\n",
        "        slider.observe(enforce_layer_slider_constraints, 'value')"
      ],
      "metadata": {
        "id": "pXPClJzZKm6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UIの設定と実行"
      ],
      "metadata": {
        "id": "isYxGZCdcz8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### マージ実行関数\n",
        "\n",
        "def execute_merge(b):  # ボタンのクリックイベントではbutton引数が必要\n",
        "    output_file = output_file_widget.value\n",
        "    try:\n",
        "        print(\"モデルのロードを開始します...\")\n",
        "        models = []\n",
        "        # 最後のモデルのパスとアルファ値も含める\n",
        "        all_paths = paths\n",
        "        all_alphas = sliders + [alpha_n]\n",
        "\n",
        "        for path, alpha in zip(all_paths, all_alphas):\n",
        "            if path.value and alpha.value > 0:\n",
        "                model = load_model(path.value, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "                if model is not None:\n",
        "                    models.append({\n",
        "                        \"weights\": model,\n",
        "                        \"alpha\": alpha.value  # .valueを追加\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"Error: model loading failed. Skip this model.\")\n",
        "\n",
        "        if len(models) == 0:\n",
        "            print(\"Error: At least one model is required for merging.\")\n",
        "        else:\n",
        "            for idx, model in enumerate(models):\n",
        "                print(f\"model{idx+1} keys: {list(model['weights'].keys())[:5]} ...\")\n",
        "\n",
        "            print(\"モデルをレイヤーごとにマージ中...\")\n",
        "            merged_weights = merge_multiple_models(\n",
        "                models=models,\n",
        "                alpha=None,  # alpha引数は不要なので削除するか、Noneを渡す\n",
        "                layer_sliders=layer_sliders,\n",
        "                use_alpha_checkboxes=use_alpha_checkboxes\n",
        "            )\n",
        "\n",
        "            print(f\"マージされたモデルを保存します: {output_file}\")\n",
        "            save_merged_model(merged_weights, output_file)\n",
        "            print(\"マージ完了！\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"エラーが発生しました: {e}\")\n",
        "        raise e  # エラーの詳細を表示"
      ],
      "metadata": {
        "id": "Nug5nf7MTBOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memo\n",
        "```Python\n",
        "# UI設定\n",
        "path1 = \"https://huggingface.co/casque/majicmixRealistic_v6/resolve/main/majicmixRealistic_v6.safetensors\" #@param {type:\"string\"}\n",
        "path2 = \"/content/drive/MyDrive/sd-webui-google-colab-setup/stable-diffusion-webui/models/checkpoints/merged_model_chillre_majic.safetensors\"  #@param {type:\"string\"}\n",
        "path3 = \"https://civitai.com/api/download/models/279964?type=Model&format=SafeTensor&size=full&fp=fp16\" #@param {type:\"string\"}\n",
        "path4 = \"https://civitai.com/api/download/models/90505?type=Model&format=SafeTensor&size=full&fp=fp32\"  #@param {type:\"string\"}\n",
        "path5 = \"\" #@param {type:\"string\"}\n",
        "path6 = \"\"  #@param {type:\"string\"}\n",
        "```"
      ],
      "metadata": {
        "id": "XxpiFgimlqMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### UIの表示と実行ボタン\n",
        "\n",
        "#@markdown ### チェックボックスに **✓ を入れる (オン, `True`) と、そのレイヤーは `alpha` 値でマージ** されます。\n",
        "#@markdown ### チェックボックスに **✓ を入れない (オフ, `False`) と、そのレイヤーは個別に設定された比率でマージ** されます。\n",
        "\n",
        "merge_button = widgets.Button(description=\"マージ実行\")\n",
        "merge_button.on_click(execute_merge)  # on_clickに直接関数を渡す\n",
        "\n",
        "ui = widgets.VBox([\n",
        "    item for sublist in [\n",
        "        [*paths, output_file_widget],\n",
        "        sliders + [alpha_n],\n",
        "        *[[use_alpha_checkboxes[layer]] + layer_sliders[layer] for layer in layer_names],\n",
        "        [merge_button]  # 修正したボタンを追加\n",
        "    ] for item in sublist\n",
        "])\n",
        "display(ui)"
      ],
      "metadata": {
        "id": "QSriTA_ETCXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}