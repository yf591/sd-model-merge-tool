{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzdUoWk1pG7iRcjAunjgLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yf591/sd-model-merge-tool/blob/main/05_Merge_Lora_Model_Ver1_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loraモデル同士のマージ（MyDriveからのロードのみを想定）"
      ],
      "metadata": {
        "id": "RYG33y0fFdis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7sapCdxlK33b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from safetensors.torch import load_file, save_file\n",
        "from typing import List, Dict\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "-7BpXJSeKrvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 関数の定義（設定）\n",
        "\n",
        "def load_lora_weights(lora_path):\n",
        "    \"\"\"LoRAファイルの重みを読み込む\"\"\"\n",
        "    try:\n",
        "        return load_file(lora_path, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    except Exception as e:\n",
        "        print(f\"エラー: LoRAファイルの読み込みに失敗しました ({lora_path}): {e}\")\n",
        "        return None\n",
        "\n",
        "def merge_lora_weights(lora_weights_list, alpha_list):\n",
        "    \"\"\"複数のLoRA重みをマージする\"\"\"\n",
        "    merged_weights = {}\n",
        "\n",
        "    # 初めのLoRAのキー構造を取得\n",
        "    base_keys = set(lora_weights_list[0].keys())\n",
        "\n",
        "    for key in base_keys:\n",
        "        weights_to_merge = []\n",
        "        valid_alphas = []\n",
        "        for weights, alpha in zip(lora_weights_list, alpha_list):\n",
        "            if key in weights:\n",
        "                 weights_to_merge.append(weights[key])\n",
        "                 valid_alphas.append(alpha)\n",
        "            else:\n",
        "                print(f\"スキップ: {key}\")\n",
        "        if weights_to_merge:\n",
        "           try:\n",
        "               merged_weights[key] = sum(\n",
        "                   alpha * weight for alpha, weight in zip(valid_alphas, weights_to_merge)\n",
        "               )\n",
        "           except Exception as e:\n",
        "                print(f\"スキップ: {key}, Error: {e}\")\n",
        "        else:\n",
        "            print(f\"情報: レイヤー {key} に対応する重みが見つからないため、最初のLoRAの重みを使用します。\")\n",
        "            merged_weights[key] = lora_weights_list[0][key]\n",
        "    return merged_weights\n",
        "\n",
        "def save_merged_lora(merged_weights, output_path):\n",
        "    \"\"\"マージしたLoRAを保存する\"\"\"\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    save_file(merged_weights, output_path)\n",
        "    print(f\"マージ済みLoRAを {output_path} に保存しました。\")"
      ],
      "metadata": {
        "id": "dPbY6wY5KvTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### UI設定\n",
        "\n",
        "#@markdown ### マージするLoraモデルを設定\n",
        "num_loras = 2 #@param {type:\"integer\"}\n",
        "\n",
        "# パスとアルファ値を格納するリストを初期化\n",
        "lora_files = []\n",
        "sliders = []\n",
        "alpha_n = None\n",
        "\n",
        "# パス入力UIの生成\n",
        "for i in range(num_loras):\n",
        "    lora_files.append(widgets.Text(value=\"\", description=f\"LoRA{i+1}\", layout=widgets.Layout(width='75%')))\n",
        "\n",
        "# アルファ値設定UIの生成\n",
        "if num_loras > 1:\n",
        "   sliders = [widgets.FloatSlider(value=1/num_loras, min=0, max=1, step=0.01, description=f\"Alpha{i+1}\", layout=widgets.Layout(width='50%')) for i in range(num_loras-1)]\n",
        "   alpha_n = widgets.FloatText(value=1-sum([slider.value for slider in sliders]), description=f\"Alpha{num_loras}\", layout=widgets.Layout(width='50%'), disabled = True)\n",
        "else:\n",
        "    alpha_n = widgets.FloatText(value=1, description=\"Alpha1\", layout=widgets.Layout(width='50%'), disabled=True)\n",
        "\n",
        "\n",
        "def enforce_alpha_constraints(*args):\n",
        "    total_alpha = sum(slider.value for slider in sliders)\n",
        "    if total_alpha > 1.0:\n",
        "        for slider in sliders:\n",
        "            slider.value = slider.value / total_alpha\n",
        "    alpha_n.value = 1 - total_alpha\n",
        "\n",
        "for slider in sliders:\n",
        "    slider.observe(enforce_alpha_constraints, 'value')\n",
        "\n",
        "# アウトプット先の設定\n",
        "output_file_widget = widgets.Text(value=\"/content/drive/MyDrive/sd-webui-google-colab-setup/stable-diffusion-webui/models/loras/merged_lora.safetensors\", description=\"Output\", layout=widgets.Layout(width='75%'))"
      ],
      "metadata": {
        "id": "EHBkBZt-K7Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaovklxbKoPe"
      },
      "outputs": [],
      "source": [
        "#@title ### マージ実行関数\n",
        "\n",
        "def execute_merge():\n",
        "    lora_path_and_alphas = []\n",
        "    all_alphas = sliders + [alpha_n]\n",
        "    for path, alpha in zip(lora_files, all_alphas):\n",
        "        if path.value and alpha.value > 0:\n",
        "           lora_path_and_alphas.append({\n",
        "               \"path\": path.value,\n",
        "               \"alpha\": alpha.value\n",
        "           })\n",
        "\n",
        "\n",
        "    output_path = output_file_widget.value\n",
        "    try:\n",
        "        lora_weights_list = []\n",
        "        alpha_list = []\n",
        "        for item in lora_path_and_alphas:\n",
        "            print(f\"LoRAファイルを読み込み中: {item['path']}\")\n",
        "            lora_weights = load_lora_weights(item['path'])\n",
        "            if lora_weights is not None:\n",
        "                 lora_weights_list.append(lora_weights)\n",
        "                 alpha_list.append(item['alpha'])\n",
        "            else:\n",
        "                print(f\"エラー: {item['path']} の読み込みに失敗しました。スキップします。\")\n",
        "\n",
        "        for idx, weights in enumerate(lora_weights_list):\n",
        "            print(f\"LoRA{idx+1} keys: {list(weights.keys())[:5]} ...\")\n",
        "\n",
        "        print(\"LoRAをマージ中...\")\n",
        "        merged_weights = merge_lora_weights(lora_weights_list, alpha_list)\n",
        "\n",
        "        print(f\"マージ済みLoRAを保存中: {output_path}\")\n",
        "        save_merged_lora(merged_weights, output_path)\n",
        "        print(\"LoRAマージ完了！\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"エラーが発生しました: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### UIの表示と実行ボタン\n",
        "\n",
        "if num_loras > 1:\n",
        "    ui = widgets.VBox(lora_files + sliders + [alpha_n])\n",
        "else:\n",
        "    ui = widgets.VBox(lora_files + [alpha_n])\n",
        "merge_button = widgets.Button(description=\"マージ実行\")\n",
        "merge_button.on_click(lambda x: execute_merge())\n",
        "display(ui, output_file_widget, merge_button)"
      ],
      "metadata": {
        "id": "-Xk7U2erMRkt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}