{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yf591/sd-model-merge-tool/blob/main/04_Merge_Model_Maker_Ver1_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3ソース（Huggin Face, Civitai, MyDrive）の2モデル単純マージ対応可\n",
        "*   Hugging Face \\* Hugging Face\n",
        "*   Civitai \\* Civitai\n",
        "*   MyDrive \\* MyDrive\n",
        "*   Hugging Face \\* Civitai\n",
        "*   Hugging Face \\* MyDrive\n",
        "*   Civitai \\* MyDrive"
      ],
      "metadata": {
        "id": "8PIJ7DV4b3MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M2ohqpp8Kg_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "\n",
        "# Hugging Face Hub, PyTorch, その他必要なライブラリをインストール\n",
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 # PyTorchを使用して深層学習モデルを操作します。CUDAバージョン（例: `cu118`）を指定\n",
        "!pip install diffusers transformers accelerate # Stable Diffusionを扱うための主要ライブラリです。モデルのロードや画像生成の操作を簡素化\n",
        "!pip install safetensors # 安全かつ軽量なモデル保存形式（`.safetensors`）をサポート\n",
        "!pip install huggingface-hub # Hugging Face Hubからモデルをダウンロード・管理\n",
        "!pip install opencv-python # 生成した画像の前処理や後処理に使用\n",
        "!pip install numpy # 数値計算ライブラリで、モデルや画像の操作に使う\n",
        "!pip install matplotlib # 生成された画像の可視化に使う\n",
        "!pip install tqdm # プログレスバーの表示\n",
        "!pip install optuna # ハイパーパラメータ最適化\n",
        "\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "1XYyzlntWgxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from safetensors.torch import load_file, save_file\n",
        "from transformers import AutoConfig, AutoModel\n",
        "from huggingface_hub import hf_hub_download\n",
        "import requests\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "-krUdr-Wci7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# Hugging Faceで取得したTokenをこちらに貼る(トークンを非表示で入力)\n",
        "HF_TOKEN = getpass(\"Hugging FaceのRead権限のあるHF Tokenを入力してください: \")\n",
        "\n",
        "# CIVITAI_TOKEN が存在する場合、取得\n",
        "api_key = userdata.get('CIVITAI_TOKEN')\n",
        "if api_key is None:\n",
        "    print(\"Error: CIVITAI_API_KEY secret is not set.\")"
      ],
      "metadata": {
        "id": "bV_1gvhHVS4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HXUgZo5rQC4"
      },
      "outputs": [],
      "source": [
        "#@title ### 関数の定義（設定）\n",
        "\n",
        "# ヘルパー関数\n",
        "def download_model(repo_id, filename, token):\n",
        "    \"\"\"Hugging Face Hubからモデルをダウンロード\"\"\"\n",
        "    return hf_hub_download(repo_id=repo_id, filename=filename, token=token)\n",
        "\n",
        "\n",
        "def download_civitai_model(url, output_path, api_key):\n",
        "    \"\"\"Civitaiからモデルをダウンロード\"\"\"\n",
        "    try:\n",
        "        headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else None\n",
        "        response = requests.get(url, stream=True, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        with open(output_path, 'wb') as file, tqdm(\n",
        "            desc=output_path,\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as bar:\n",
        "             for data in response.iter_content(chunk_size=1024):\n",
        "                size = file.write(data)\n",
        "                bar.update(size)\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading from Civitai: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_model(path, device):\n",
        "    \"\"\"ファイルパスからモデルをロードする\"\"\"\n",
        "    try:\n",
        "        if path.startswith(\"http\"):\n",
        "            # URLの場合（Civitaiなど）は、ダウンロードしてから読み込む\n",
        "            if \"civitai.com\" in path:\n",
        "                output_path = \"/content/temp_model.safetensors\"  # 一時的な保存先パス\n",
        "                path = download_civitai_model(path, output_path, api_key)\n",
        "                if not path:\n",
        "                   return None\n",
        "                else:\n",
        "                   print(f\"Civitaiからモデルをロード: {path}\")\n",
        "                   return load_file(path, device=device) #ダウンロード後のファイルパスを渡す。\n",
        "            elif \"huggingface.co\" in path:\n",
        "                print(f\"HuggingFaceからモデルをロード: {path}\")\n",
        "                repo_id_and_file = path.split(\"huggingface.co/\")[1]\n",
        "                repo_id = repo_id_and_file.split(\"/resolve/\")[0]\n",
        "                filename = repo_id_and_file.split(\"/\")[-1]\n",
        "                path = download_model(repo_id, filename, HF_TOKEN)\n",
        "                return load_file(path, device=device)\n",
        "            else:\n",
        "                print(\"Error: HTTP URL not recognized, use HuggingFace or Civitai Model.\")\n",
        "                return None\n",
        "\n",
        "        if path.startswith(\"/content/drive\"):\n",
        "          # Google Drive のパスの場合\n",
        "            print(f\"Google Driveからモデルをロード: {path}\")\n",
        "            return load_file(path, device=device)\n",
        "        else:\n",
        "          print(\"Error: Incorrect Model Path.\")\n",
        "          return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def merge_weights(model1, model2, alpha):\n",
        "    \"\"\"指定されたレイヤーで重みをマージする\"\"\"\n",
        "    merged = {}\n",
        "    for key in model1.keys():\n",
        "        if key in model2:\n",
        "            layer_weight = alpha\n",
        "            try:\n",
        "                merged[key] = layer_weight * model1[key] + (1 - layer_weight) * model2[key]\n",
        "            except Exception as e:\n",
        "                print(f\"Skipped key: {key}, Error: {e}\")\n",
        "                merged[key] = model1[key]  # エラーが発生したら model1 の重みをそのまま使う\n",
        "        else:\n",
        "            merged[key] = model1[key]\n",
        "    return merged\n",
        "\n",
        "\n",
        "def save_merged_model(merged_weights, output_path):\n",
        "    \"\"\"マージ済みモデルを保存\"\"\"\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    save_file(merged_weights, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**使い方**\n",
        "\n",
        "*   **MyDriveにあるモデル:**\n",
        "    `path1` に、Google Drive 内のモデルファイルのパスを指定します。\n",
        "    \n",
        "    例:`\"/content/drive/MyDrive/sd-webui-google-colab-setup/stable-diffusion-webui/models/checkpoints/chilled_remix_v2.safetensors\"`\n",
        "\n",
        "*   **Hugging Face Hub のモデル:**\n",
        "    `path1` または `path2` に、モデルのdownload linkを入力します。\n",
        "    \n",
        "    例:`\"https://huggingface.co/casque/majicmixRealistic_v6/resolve/main/majicmixRealistic_v6.safetensors\"`\n",
        "    この場合、HuggingFaceからモデルをダウンロードします。\n",
        "\n",
        "*   **Civitai のモデル:**\n",
        "    `path1` または `path2` に、Civitai のモデルダウンロード URL を指定します。\n",
        "    \n",
        "    例:`\"https://civitai.com/api/download/models/303526?type=Model&format=SafeTensor&size=full&fp=fp16?token={api_key}\"`\n",
        "    この場合、`CIVITAI_TOKEN` が設定されている必要があり、Civitaiからモデルをダウンロードします。"
      ],
      "metadata": {
        "id": "bSHZtbi1dr4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### UI設定\n",
        "\n",
        "#@markdown ### マージするモデルを設定\n",
        "path1 = \"https://huggingface.co/casque/majicmixRealistic_v6/resolve/main/majicmixRealistic_v6.safetensors\" #@param {type:\"string\"}\n",
        "path2 = \"https://civitai.com/api/download/models/90505?type=Model&format=SafeTensor&size=full&fp=fp32\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### アウトプット先を指定\n",
        "output_file = \"/content/drive/MyDrive/sd-webui-google-colab-setup/stable-diffusion-webui/models/checkpoints/merged_model_sample.safetensors\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### マージ比率の設定\n",
        "alpha = 0.5 #@param {type:\"slider\", min:0.0, max:1.0, step:0.001}"
      ],
      "metadata": {
        "id": "pXPClJzZKm6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ###実行\n",
        "try:\n",
        "    print(\"モデルのロードを開始します...\")\n",
        "    model1 = load_model(path1, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model2 = load_model(path2, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if model1 is None or model2 is None:\n",
        "         print(\"モデルのロードに失敗しました。\")\n",
        "    else:\n",
        "\n",
        "        # ここにモデルのキーを出力するコードを追加\n",
        "        print(\"model1 keys:\", list(model1.keys())[:5] , \"...\")\n",
        "        print(\"model2 keys:\", list(model2.keys())[:5] , \"...\")\n",
        "\n",
        "        print(\"モデルをレイヤーごとにマージ中...\")\n",
        "        merged_weights = merge_weights(model1, model2, alpha)\n",
        "\n",
        "        print(f\"マージされたモデルを保存します: {output_file}\")\n",
        "        save_merged_model(merged_weights, output_file)\n",
        "        print(\"マージ完了！\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"エラーが発生しました: {e}\")"
      ],
      "metadata": {
        "id": "E2wcOpy7NvmQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}